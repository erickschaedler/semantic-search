"""
Interface Streamlit para o Chat com Busca SemÃ¢ntica em Manuais
"""

import streamlit as st
import chromadb
from chromadb.config import Settings
from rag import (
    get_openai_client,
    process_pdf_pipeline,
    ask_question_pipeline,
    get_or_create_collection
)

# ============== CONFIGURAÃ‡ÃƒO DA PÃGINA ==============

st.set_page_config(
    page_title="Chat com Manuais",
    page_icon="ðŸ“š",
    layout="centered"
)

st.title("ðŸ“š Chat com Manuais")
st.caption("FaÃ§a perguntas sobre seus manuais tÃ©cnicos")


# ============== INICIALIZAÃ‡ÃƒO DO ESTADO ==============

def init_session_state():
    """Inicializa variÃ¡veis de sessÃ£o."""
    if "messages" not in st.session_state:
        st.session_state.messages = []

    if "processed_files" not in st.session_state:
        st.session_state.processed_files = []

    if "chroma_client" not in st.session_state:
        st.session_state.chroma_client = chromadb.Client(Settings(
            anonymized_telemetry=False
        ))

    if "collection" not in st.session_state:
        st.session_state.collection = get_or_create_collection(
            st.session_state.chroma_client,
            "manuals"
        )


init_session_state()


# ============== SIDEBAR - CONFIGURAÃ‡ÃƒO ==============

with st.sidebar:
    st.header("âš™ï¸ ConfiguraÃ§Ã£o")

    # API Key
    api_key = st.text_input(
        "OpenAI API Key",
        type="password",
        help="Sua chave da API OpenAI",
        value=st.secrets.get("OPENAI_API_KEY", "") if hasattr(st, "secrets") else ""
    )

    if api_key:
        st.success("âœ“ API Key configurada")
    else:
        st.warning("âš ï¸ Insira sua API Key")

    st.divider()

    # Upload de PDF
    st.header("ðŸ“„ Upload de Manuais")

    uploaded_files = st.file_uploader(
        "Selecione PDFs",
        type=["pdf"],
        accept_multiple_files=True,
        help="FaÃ§a upload de 1 ou mais manuais em PDF"
    )

    if uploaded_files and api_key:
        for uploaded_file in uploaded_files:
            if uploaded_file.name not in st.session_state.processed_files:
                with st.spinner(f"Processando {uploaded_file.name}..."):
                    try:
                        client = get_openai_client(api_key)
                        num_chunks = process_pdf_pipeline(
                            uploaded_file,
                            client,
                            st.session_state.collection,
                            uploaded_file.name
                        )
                        st.session_state.processed_files.append(uploaded_file.name)
                        st.success(f"âœ“ {uploaded_file.name} ({num_chunks} chunks)")
                    except Exception as e:
                        st.error(f"Erro: {str(e)}")

    # Lista de arquivos processados
    if st.session_state.processed_files:
        st.divider()
        st.subheader("ðŸ“ Manuais carregados")
        for file in st.session_state.processed_files:
            st.text(f"â€¢ {file}")

        if st.button("ðŸ—‘ï¸ Limpar tudo", type="secondary"):
            st.session_state.messages = []
            st.session_state.processed_files = []
            st.session_state.chroma_client = chromadb.Client(Settings(
                anonymized_telemetry=False
            ))
            st.session_state.collection = get_or_create_collection(
                st.session_state.chroma_client,
                "manuals"
            )
            st.rerun()


# ============== ÃREA PRINCIPAL - CHAT ==============

# Exibe mensagens do histÃ³rico
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

        # Mostra fontes se houver
        if message["role"] == "assistant" and "sources" in message:
            with st.expander("ðŸ“– Trechos relevantes"):
                for i, source in enumerate(message["sources"], 1):
                    st.markdown(f"**Trecho {i}:**")
                    st.text(source[:500] + "..." if len(source) > 500 else source)
                    st.divider()

# Input do usuÃ¡rio
if prompt := st.chat_input("FaÃ§a uma pergunta sobre o manual..."):
    # ValidaÃ§Ãµes
    if not api_key:
        st.error("âš ï¸ Configure sua API Key na barra lateral")
        st.stop()

    if not st.session_state.processed_files:
        st.error("âš ï¸ FaÃ§a upload de pelo menos um manual PDF")
        st.stop()

    # Adiciona mensagem do usuÃ¡rio
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("user"):
        st.markdown(prompt)

    # Gera resposta
    with st.chat_message("assistant"):
        with st.spinner("Buscando no manual..."):
            try:
                client = get_openai_client(api_key)

                # Prepara histÃ³rico (Ãºltimas 5 mensagens)
                chat_history = [
                    {"role": m["role"], "content": m["content"]}
                    for m in st.session_state.messages[-10:]
                    if m["role"] in ["user", "assistant"]
                ]

                # Faz a pergunta
                answer, sources = ask_question_pipeline(
                    prompt,
                    client,
                    st.session_state.collection,
                    n_results=3,
                    chat_history=chat_history[:-1]  # Exclui a pergunta atual
                )

                st.markdown(answer)

                # Mostra fontes
                if sources:
                    with st.expander("ðŸ“– Trechos relevantes"):
                        for i, source in enumerate(sources, 1):
                            st.markdown(f"**Trecho {i}:**")
                            st.text(source[:500] + "..." if len(source) > 500 else source)
                            st.divider()

                # Salva no histÃ³rico
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": answer,
                    "sources": sources
                })

            except Exception as e:
                st.error(f"Erro ao processar: {str(e)}")


# ============== FOOTER ==============

st.divider()
st.caption("ðŸ’¡ Dica: Quanto mais especÃ­fica a pergunta, melhor a resposta!")
